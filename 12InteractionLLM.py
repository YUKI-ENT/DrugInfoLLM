import psycopg2
import requests
import json
import re, ast
import time
from datetime import datetime
from tqdm import tqdm

# --- è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ ---
with open("config.json", "r", encoding="utf-8") as f:
    config = json.load(f)
db_conf = config["db"]
ollama_url = config.get("ollama_url", "http://localhost:11434/api/generate")
ollama_model = config.get("ollama_model", "gemma3:12b")
ollama_timeout = config.get("ollama_timeout", 60)
chunk_length = config.get("chunk_length", 3000)
chunk_overlap = config.get("chunk_overlap", 500)
pause_second = config.get("gpu_cooling_wait", 30) #GPUåŠ ç†±å¯¾ç­–ã€‚10ä»¶å‡¦ç†ã™ã‚‹ã”ã¨ã«ã“ã®ç§’æ•°å‡¦ç†ã‚’ä¸­æ–­ã™ã‚‹

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèª ---
confirm = input(f"ä½µç”¨æƒ…å ±ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã‚’è¡Œã„ã¾ã™ã€‚LLMã‚’ä½¿ã†ã®ã§ã‹ãªã‚Šã®æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ãŒã€ã‚ˆã‚ã—ã„ã§ã™ã‹ï¼Ÿ (y/n): ")
if confirm.lower() != 'y':
    print("ä¸­æ­¢ã—ã¾ã—ãŸã€‚")
    exit()

# --- DBæ¥ç¶š ---
conn = psycopg2.connect(**db_conf)
cursor = conn.cursor()

# --- DROPç¢ºèªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ---
start_id = 0
progress_file = "progress_interaction.json"
drop_confirm = input("æ—¢å­˜ã® drug_interaction ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å‰Šé™¤ã—ã¦ä½œã‚Šç›´ã—ã¾ã™ã‹ï¼Ÿ (Y/n): ").strip().lower()
if drop_confirm == "y":
    print("ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å‰Šé™¤ã—ã¦ä½œã‚Šç›´ã—ã¾ã™ã€‚")
    cursor.execute("DROP TABLE IF EXISTS drug_interaction")
    cursor.execute("""
    CREATE TABLE drug_interaction (
        id SERIAL PRIMARY KEY,
        id_druginformation INTEGER,
        yj_code VARCHAR(16),
        agent TEXT,
        category TEXT,
        interaction_type TEXT,
        description TEXT,
        AImodel VARCHAR(64),
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    )
    """)
    conn.commit()
    print("ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
else:
    print("ãƒ†ãƒ¼ãƒ–ãƒ«å‰Šé™¤ãƒ»å†ä½œæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")# ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
    # --- å‡¦ç†å†é–‹ãƒã‚¤ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿ ---
    process_confirm = input("å‰å›ã®ä¸­æ–­éƒ¨ä½ã‹ã‚‰å†é–‹ã—ã¾ã™ã‹ï¼Ÿ n:å…ˆé ­ã‹ã‚‰(Y/n): ").strip().lower()
    if process_confirm != "n":
        try:
            with open(progress_file, "r", encoding="utf-8") as pf:
                saved = json.load(pf)
                start_id = saved.get("last_id", 0)
                print(f"å‰å›ã®å‡¦ç†ä½ç½®ï¼ˆid_druginformation={start_id}ï¼‰ã‹ã‚‰å†é–‹ã—ã¾ã™ã€‚")
        except FileNotFoundError:
            print("é€²æ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æœ€åˆã‹ã‚‰å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    else:
        print("æœ€åˆã‹ã‚‰å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚")

log_file = open("interaction_debug.log", "a", encoding="utf-8")

# ç›¸äº’ä½œç”¨ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
# cursor.execute("SELECT yj_code, content FROM drug_filedata WHERE section_key = 'interactions' LIMIT 100000 OFFSET 1000")
cursor.execute("""
    SELECT id_druginformation, yj_code, content 
    FROM drug_filedata 
    WHERE section_key = 'interactions' AND id_druginformation > %s
    ORDER BY id_druginformation
""", (start_id,))
rows = cursor.fetchall()

# Ollamaå‘¼ã³å‡ºã—é–¢æ•°
def call_ollama(prompt):
    try:
        response = requests.post(
            ollama_url,
            json={"model": ollama_model, "prompt": prompt, "stream": False},
            timeout=ollama_timeout
        )
        data = response.json()
        raw = data.get("response", "")
        
        return raw
    except Exception as e:
        return str(e)

# ã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹é™¤å»
# def strip_code_fence(text):
#     return text.strip().removeprefix("```json").removesuffix("```").strip()
def strip_code_fence(text, log_file):
    """
    å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ JSON é…åˆ—ã¾ãŸã¯ Python æ§‹æ–‡é…åˆ—ã‚’æŠ½å‡ºãƒ»ãƒ‘ãƒ¼ã‚¹ã—ã€log_file ã«ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã€‚
    """
    # å¿œç­”æœ¬æ–‡ãƒ­ã‚°å‡ºåŠ›
    log_file.write("--- strip_code_fence(): å¿œç­”æœ¬æ–‡ ---\n")
    log_file.write(text + "\n")
    log_file.write("-----------------------------------\n")

   # ã™ã§ã«Pythonã®list/dictã¨ã—ã¦æ¸¡ã•ã‚ŒãŸå ´åˆã¯ãã®ã¾ã¾è¿”ã™
    if isinstance(text, (list, dict)):
        return text

    # æ–‡å­—åˆ—ã‹ã‚‰ [] ã‚’æŠ½å‡º
    array_matches = re.findall(r"\[[\s\S]*?\]", text)
    for candidate in array_matches:
        try:
            log_file.write(f"âœ“ JSONã¨ã—ã¦æˆåŠŸ\n")
            return json.loads(candidate)
        except json.JSONDecodeError:
            pass
        try:
            return ast.literal_eval(candidate)
        except Exception:
            continue

    return None

def split_text_safely(text, max_len=3000, overlap=500):
    """
    é•·æ–‡ã‚’ max_len æ–‡å­—ä»¥å†…ã®ãƒãƒ£ãƒ³ã‚¯ã«æ”¹è¡Œå˜ä½ã§å®‰å…¨ã«åˆ†å‰²ã€‚
    å„ãƒãƒ£ãƒ³ã‚¯ã¯ overlap æ–‡å­—ã ã‘å‰ã®ãƒãƒ£ãƒ³ã‚¯ã®æœ«å°¾ã¨é‡è¤‡ã•ã›ã‚‹ã€‚

    :param text: åˆ†å‰²å¯¾è±¡ã®æ–‡å­—åˆ—
    :param max_len: å„ãƒãƒ£ãƒ³ã‚¯ã®æœ€å¤§æ–‡å­—æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3000ï¼‰
    :param overlap: ãƒãƒ£ãƒ³ã‚¯é–“ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æ–‡å­—æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 500ï¼‰
    :return: åˆ†å‰²ã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆ
    """
    paragraphs = text.split("\n")
    chunks = []
    current_chunk = ""

    for para in paragraphs:
        # æ”¹è¡Œ + 1 æ–‡å­—åˆ†ã‚’è¦‹è¶Šã—ã¦ä½™è£•ã‚’è¦‹ã‚‹
        if len(current_chunk) + len(para) + 1 <= max_len:
            current_chunk += para + "\n"
        else:
            # ãƒãƒ£ãƒ³ã‚¯å®Œæˆ
            chunks.append(current_chunk.strip())

            # overlapåˆ†ã‚’æ®‹ã™ï¼ˆæ”¹è¡Œè¾¼ã¿ã§ç¢ºä¿ï¼‰
            tail = current_chunk[-overlap:] if len(current_chunk) > overlap else current_chunk
            current_chunk = tail + para + "\n"

    if current_chunk.strip():
        chunks.append(current_chunk.strip())

    return chunks

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
for idx, (id_druginformation, yj_code, content) in enumerate(tqdm(rows, desc="LLMå‡¦ç†ä¸­"), 1):
    chunks = split_text_safely(content, max_len=chunk_length, overlap=chunk_overlap)
    for part_idx, chunk in enumerate(chunks):
        prompt = (
            f"ä»¥ä¸‹ã¯åŒ»è–¬å“ã®ã€Œç›¸äº’ä½œç”¨ã€ã«é–¢ã™ã‚‹è¨˜è¼‰ã§ã™ï¼ˆåˆ†å‰²{part_idx+1}/{len(chunks)}ï¼‰ã€‚\n"
            f"ã“ã®æ–‡ç« ã‹ã‚‰ã€ç›¸äº’ä½œç”¨ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã™ã¹ã¦ã®è–¬å‰¤åï¼ˆä¸€èˆ¬åã¾ãŸã¯å•†å“åï¼‰ã¨è–¬åŠ¹ç¾¤åã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚\n\n"
            f"ç‰¹ã«ã€è–¬åŠ¹ç¾¤ï¼ˆä¾‹ï¼šã‚«ãƒ†ã‚³ãƒ¼ãƒ«ã‚¢ãƒŸãƒ³è£½å‰¤ã€ã‚­ã‚µãƒ³ãƒãƒ³ç³»è–¬å‰¤ãªã©ï¼‰ã®ä¸­ã«å€‹åˆ¥è–¬å‰¤ï¼ˆä¾‹ï¼šã‚¢ãƒ‰ãƒ¬ãƒŠãƒªãƒ³ã€ãƒ†ã‚ªãƒ•ã‚£ãƒªãƒ³ç­‰ï¼‰ãŒåˆ—æŒ™ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€\n"
            f"ã‚«ãƒƒã‚³æ›¸ãå†…ã®ã™ã¹ã¦ã®è–¬å‰¤åï¼ˆä¾‹ï¼šã‚­ãƒ‹ã‚¸ãƒ³ã€ãƒ‘ãƒ­ã‚­ã‚»ãƒãƒ³ãªã©ï¼‰ã‚’ãã‚Œãã‚Œå±•é–‹ã—ã€1ã¤ãšã¤ç‹¬ç«‹ã—ãŸé …ç›®ã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n"
            f"ä¾‹ãˆã°ä»¥ä¸‹ã®ã‚ˆã†ãªæ–‡ç« ï¼š\n"
            f"ã€ŒCYP2D6é˜»å®³ä½œç”¨ã‚’æœ‰ã™ã‚‹è–¬å‰¤ï¼ˆã‚­ãƒ‹ã‚¸ãƒ³ã€ãƒ‘ãƒ­ã‚­ã‚»ãƒãƒ³ç­‰ï¼‰ã€\n"
            f"ã¨ã„ã†è¨˜è¼‰ãŒã‚ã‚Œã°ã€ä»¥ä¸‹ã®ã‚ˆã†ã«å±•é–‹ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š\n\n"
            "[\n"
            "  {\n"
            "    \"agent\": \"ã‚­ãƒ‹ã‚¸ãƒ³\",\n"
            "    \"category\": \"CYP2D6é˜»å®³å‰¤\",\n"
            "    \"interaction_type\": \"ä½µç”¨æ³¨æ„\",\n"
            "    \"description\": \"æœ¬å‰¤ã®ä½œç”¨ãŒå¢—å¼·ã™ã‚‹ãŠãã‚ŒãŒã‚ã‚‹ã®ã§ã€æœ¬å‰¤ã‚’æ¸›é‡ã™ã‚‹ãªã©è€ƒæ…®ã™ã‚‹ã“ã¨ã€‚\"\n"
            "  },\n"
            "  {\n"
            "    \"agent\": \"ãƒ‘ãƒ­ã‚­ã‚»ãƒãƒ³\",\n"
            "    \"category\": \"CYP2D6é˜»å®³å‰¤\",\n"
            "    \"interaction_type\": \"ä½µç”¨æ³¨æ„\",\n"
            "    \"description\": \"æœ¬å‰¤ã®ä½œç”¨ãŒå¢—å¼·ã™ã‚‹ãŠãã‚ŒãŒã‚ã‚‹ã®ã§ã€æœ¬å‰¤ã‚’æ¸›é‡ã™ã‚‹ãªã©è€ƒæ…®ã™ã‚‹ã“ã¨ã€‚\"\n"
            "  }\n"
            "]\n\n"
            "ã“ã®ã‚ˆã†ã«ã€æ‹¬å¼§å†…ã«è–¬å‰¤åãŒä¸¦ã‚“ã§ã„ã‚‹å ´åˆã¯ã€ãã‚Œãã‚Œã‚’åˆ¥ã® JSON ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n\n"
            "ä»¥ä¸‹ã®å½¢å¼ã® JSON é…åˆ—ã§è¿”ã—ã¦ãã ã•ã„ï¼ˆã™ã¹ã¦ã®è–¬å‰¤ã«ã¤ã„ã¦1ã¤ãšã¤ï¼‰ï¼š\n\n"
            "[\n"
            "  {\n"
            "    \"agent\": \"è–¬å‰¤åã¾ãŸã¯è–¬åŠ¹ç¾¤åï¼ˆã§ãã‚‹é™ã‚Šå€‹åˆ¥è–¬å‰¤åï¼‰\",\n"
            "    \"category\": \"è–¬åŠ¹åˆ†é¡ï¼ˆä¸æ˜ãªå ´åˆã¯è¿‘ã„è¡¨ç¾ï¼‰\",\n"
            "    \"interaction_type\": \"ä½µç”¨æ³¨æ„ ã¾ãŸã¯ ç¦å¿Œ\",\n"
            "    \"description\": \"ç›¸äº’ä½œç”¨ã®å†…å®¹ï¼ˆè–¬åŠ¹ç¾¤åã«å¯¾ã™ã‚‹èª¬æ˜ã‚’å…±é€šã§ä½¿ã£ã¦ã‚ˆã„ï¼‰\"\n"
            "  }\n"
            "]\n\n"
            "çµ¶å¯¾ã«ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã‚’å¤‰æ›´ã—ãªã„ã§ãã ã•ã„ã€‚è¿”ç­”ã¯ã€å³å¯†ãª JSON å½¢å¼ï¼ˆãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã§å›²ã¾ã‚ŒãŸæ–‡å­—åˆ—ï¼‰ã§ã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n"
            "ã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã‚„ <think> ã®ã‚ˆã†ãªèª¬æ˜æ–‡ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚\n\n"
            "ä»¥ä¸‹ãŒæ·»ä»˜æ–‡æ›¸ã§ã™ï¼š\n"
            f"{chunk}"
        )

        # ãƒ­ã‚°ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ›¸ãè¾¼ã‚€
        log_file.write("======================================================================================\n")
        log_file.write(f"\n[{datetime.now()}]\n[{yj_code}] (chunk {part_idx+1})\n--- Prompt(model:{ollama_model}) ---\n{prompt}\n")
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ï¼ˆçŸ­ç¸®è¡¨ç¤ºï¼‰
        # print(f"\n[{yj_code}] (chunk {part_idx+1})\n--- Prompt(model:{ollama_model}) ---\n{prompt[:150]}\n")
        print(f"[{yj_code}] (chunk {part_idx+1}/{len(chunks)}) ollama({ollama_model})å•ã„åˆã‚ã›ä¸­...")
        
        start = time.time()

        response = call_ollama(prompt)
        response = strip_code_fence(response, log_file)

        elapsed = time.time() - start

        log_file.write(f"--- Response (model: {ollama_model})---\n{response}\n")
        log_file.write(f"[{datetime.now()}] response time: {elapsed:.2f} sec\n")
        print(f"[Response](model: {ollama_model})\n{response}...\n---")
        print(f"[{datetime.now()}] response time: {elapsed:.2f} sec\n")

        try:
            inserted_number = 0
            data = response if isinstance(response, list) else json.loads(response)
            for entry in data:
                try:
                    cursor.execute("""
                        INSERT INTO drug_interaction (id_druginformation, yj_code, agent, category, interaction_type, description, created_at, AImodel)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                    """, (
                        id_druginformation,
                        yj_code,
                        entry.get("agent", ""),
                        entry.get("category", ""),
                        entry.get("interaction_type", ""),
                        entry.get("description", ""),
                        datetime.now(),
                        ollama_model
                    ))
                    conn.commit()
                    log_file.write(f"--- SQL insert success!  ---\n")
                    inserted_number += 1
                except Exception as insert_err:
                    log_file.write(f"--- SQL INSERT Error ---\n{insert_err}\nentry={entry}\n")
                    print(f"--- SQL INSERT Error ---\n{insert_err}\nentry={entry}\n")
        except Exception as e:
            log_file.write(f"--- JSON Parse Error (chunk {part_idx+1}) ---\n{e}\n{response}\n")
            print(f"--- JSON Parse Error (chunk {part_idx+1}) ---\n{e}\n{response}\n")
        if inserted_number > 0:
            print(f"SQL{inserted_number}ä»¶é€ä¿¡æˆåŠŸ\n")    
        
    # ğŸ”„ é€²æ—ä¿å­˜
    with open(progress_file, "w", encoding="utf-8") as pf:
        json.dump({"last_id": id_druginformation}, pf)

    # 10ä»¶ã”ã¨ã«ä¼‘æ­¢
    if idx % 10 == 0:
        print(f"\n--- {idx}ä»¶å‡¦ç†æ¸ˆã¿ã€{pause_second}ç§’ä¼‘æ­¢ ---\n")
        log_file.write(f"\n--- {idx}ä»¶å‡¦ç†æ¸ˆã¿ã€{pause_second}ç§’ä¼‘æ­¢ ---\n")
        time.sleep(pause_second)

# å¾Œå‡¦ç†
#conn.commit()
cursor.close()
conn.close()
log_file.close()
